# Introduction

To the extent that species interactions are important for community assembly, ecologists generally expect them to leave a signature on species' co-occurrence patterns.  But using that signature to infer the underlying species interactions has been much harder.  Disagreements about how to draw these inferences led to an acrimonious, decade-long argument among community ecologists [@lewin_santa_1983], where essentially all of the proposed statistical approaches were criticized for having high error rates, a poor match with the underlying ecological questions, computational infeasibility, or all three [@connor_assembly_1979; @strong_ecological_1984; @hastings_can_1987]. [[**The next two sentences are unnecessarily confrontational and should probably be removed**]] *Despite these difficulties, ecologists have considered the underlying questions so important that, for the last few decades, they have continued to address them with whatever methods were available, even when these methods are known to perform poorly. For example, the False Discovery Rates above 95% demonstrated in @gotelli_empirical_2009 have not prevented wide adoption of method proposed in that paper*

During the time that ecologists have struggled to identify the interactions among dozens of species, bioinformaticians have largely solved the analogous problem of estimating interactions among *thousands* of genes from their co-expression levels (e.g. @friedman_sparse_2008). The discrepancy is due to the fact that ecologists have focused, almost exclusively, on overall co-occurrence rates [@connor_assembly_1979; @gotelli_empirical_2009; @gilpin_factors_1982; @veech_probabilistic_2013], and most of the test statistics in common use are actually minor variations on the sample correlation [*evidence to be added to Chapter 2*]. As ecologists know, however, the correlation between two species will often reflect other factors beyond their direct pairwise interactions (Figure 1, *to be added*). While some narrowly-focused methods have been proposed for incorporating a small number of specific factors into ecologists' null models at a time [@lessard_strong_2011], we still don't have a good way to scale these approaches up for cases with many factors acting simultaneously.

In other fields, scientists have a number of procedures for controlling for the influence of extraneous factors and focusing on the direct relationship between a single pair of variables.  The most familiar of these is the partial correlation. Rather than describing the *overall* relationship between two variables across *all* conditions, partial correlations (like regression coefficients) describe the portion of the relationship that remains after the other variables in the data have been accounted for.  @harris_estimating_2015 showed that the partial correlation can do a surprisingly good job of extracting accurate information about pairwise species interactions from co-occurrence data, and that Markov networks (undirected graphical models also known as Markov random fields), which do not assume normally-distributed observations do even better (cf @azaele_inferring_2010 and @fort_statistical_2013). A Markov network defines a probability distribution over possible binary species assemblages, and its coefficients (including one coefficient describing the conditional relationship between each pair of species in the network) can be estimated by maximum likelihood.

Unfortunately, Markov networks have an intractable likelihood function whose computational complexity more than doubles each time a new species is added to the model. Thus, while Harris (2015) was able to use off-the-shelf optimization techniques to maximize the likelihood for networks of 20 species, extending the same approach to networks of 50-100 species would be completely infeasible. If ecologists want the model to account for abiotic variation among sites on the landscape, then these expensive computations need to be repeated independently for every site, increasing the computational burden even further.

In this paper, I present a different way of optimizing the likelihood, called *stochastic approximation* [@robbins_stochastic_1951; @salakhutdinov_efficient_2012], which replaces the intractable computations with tractable Monte Carlo estimates of the same quantities. Despite the sampling error introduced by this substitution, stochastic approximation provides strong guarantees for eventual convergence to the maximum likelihood estimate. This change in approach makes it feasible to estimate the interactions among hundreds of species from observational data while also accounting for possible responses to abiotic factors.

# Methods

## Markov networks

As discussed in @azaele_inferring_2010, @fort_statistical_2013, and @harris_estimating_2015, Markov networks such as the Ising model [@cipra_introduction_1987] can be used to describe community structure as follows.  Each species is represented by a binary random variable, describing whether it is present or absent.  A species’ conditional probability of presence under a given set of biotic and abiotic conditions depends on its coefficients. The coefficients linking species to one another describe their conditional associations: *all else equal*, a species will occur less often in the presence of its competitors and other species with which it is negatively associated, and more often in the presence of its mutualists.  These conditional probabilities can be combined to calculate the probability of observing any given combination of presences and absences.  For example, hypothetical assemblages including many pairs of competitively exclusive species at the same site will tend to be very improbable under the model.

Unfortunately, the extremely large number of possible assemblages makes this joint probability intractable when the number of species is large.  However, it is generally straightforward to simulate examples of assemblages that are consistent with graphical models such as these, using Monte Carlo techniques like Gibbs sampling [@salakhutdinov_efficient_2012]. Gibbs sampling is especially convenient for these models because it only requires the conditional probabilities, which are straightforward to compute (Harris 2015; Appendix). 

In each of the scenarios below, the “observed” landscapes were simulated using Gibbs sampling from a pre-specified set of “true” parameters.

## Simulated landscapes with known interactions

In order to evaluate partial correlations' ability to recover the "true" parameters that generated a presence-absence matrix of interest, I first needed to generate such matrices from known processes. 

To demonstrate that the stochastic approximation method worked, I first simulated 10 landscapes with 20 species and 500 sites, using the Gibbs sampling approach described in @harris_estimating_2015.  These landscapes had few enough species that the `rosalia` package for estimating Markov networks [@harris_rosalia_2015] could find the penalized maximum likelihood estimates for the Markov network in a reasonable amount of time.  For each of these simulated landscapes, I then fit the same model using both the exact approach from @harris_estimating_2015 and the stochastic approximation method described below.

I then simulated a large landscape with 250 species and 2500 sites, representing a large data set roughly the size of the North American Breeding Bird Survey.  Each site on the landscape was represented by 5 environmental variables, which were drawn independently from Gaussian distributions with mean 0 and standard deviation 2.

Each species was assigned two two sets of coefficients.  The coefficients determining species’ responses to the environment were each drawn from standard normal distributions.  The coefficients describing species’ pairwise interactions were drawn from a mixture of two zero-mean Gaussian distributions. 90% of the interaction coefficients were drawn from a distribution with standard deviation 0.2, while the remainder were drawn from a distribution with standard deviation 1.0. 

The coefficients described above are sufficient to define each species' conditional occurrence probability (i.e. its probability of occurrence against any given backdrop of biotic and abiotic features).  I used these conditional probabilities to produce examples of communities that were consistent with the competition parameters and with the local environmental variables via Markov chain Monte Carlo (specifically, `r n_gibbs` rounds of Gibbs sampling; see code in the Appendix). I then used the methods from the next section to attempt to infer the underlying parameters from the simulated data.

## Coefficient estimation with stochastic approximation

A Markov network describes a probability distribution over possible assemblages, and this distribution can be summarized without loss of information by its *sufficient statistics*.  For the model presented here, the sufficient statistics include: the number of occurrences for each species, the number of co-occurrences between each species, and the cross-product between the species and environment matrices [[*Appendix, not yet written*]].  One way to look at maximum likelihood estimation is that it minimizes the discrepancy between the sufficient statistics observed in the data and the average sufficient statistics produced by samples from the model [[ref?]]. Because fully-observed Markov networks, such as the ones analyzed here, have unimodal likelihood functions [@murphy_machine_2012], any iterative procedure that can reduce this discrepancy quickly enough will converge to the global maximum likelihood estimate.

The `rosalia` package reduces the discrepancy between observed and predicted sufficient statistics by calculating it exactly, averaging over *all* possible presence-absence combinations, but this approach is intractable for larger networks. Stochastic approximation [refs] is a procedure that allows us to approximate the expected values of the sufficient statistics by averaging over a more manageable number of simulated assemblages during each model-fitting iteration, while still retaining maximum likelihood convergence guarantees.  The procedure iterates through the following three steps as many times as needed (5000 for these analyses):

1: simulate a set of assemblages from the current model parameters and calculate sufficient statistics for the sample.
2: subtract the simulated sufficient statistics from the observed ones to calculate the approximate likelihood gradient
3: Adjust the model parameters to climb the approximate gradient, using a schedule of step sizes that satisfies the criteria in Chapter 6 of @powell_approximate_2007.

The specific procedure used here had the following implementation details:

The simulations in Step 1 used Gibbs sampling to generate examples of landscapes based on the model’s current parameter estimates. While the simulated landscapes produced by Gibbs sampling are serially autocorrelated, statisticians have shown that this difficulty does not prevent convergence to the maximum likelihood estimate [@younes_convergence_1999; @salakhutdinov_efficient_2012].

The approximate likelihood gradients in Step 2 match the ones from the Appendix of @harris_estimating_2015, except that they are averaged over a set of Monte Carlo samples rather than over all possible presence-absence combinations. These gradients were augmented with a momentum term equal to 0.9 [@hinton_practical_2012] and by regularizers based on a logistic prior with location 0 and scale 1.0 (for environmental responses) or 0.1 (for pairwise interactions); the pairwise interaction terms were regularized more heavily to improve identifiability and reduce overfitting for this large set of 31,125 coefficients.

The step size parameter in Step 3, $\alpha_t$, decreased after each iteration according to a generalized harmonic sequence, $\alpha_t = \alpha_0 500/(500 - t - 1)$, which satisfies the criteria in @powell_approximate_2007. $\alpha_0$ was 1.0 for species’ intercepts and environmental responses, and one tenth as large for their pairwise interaction coefficients.

# Results


![](convergence.pdf)

The squared deviations between the exact estimates produced by the `rosalia` package and the ones produced by stochastic approximation quickly decayed to negligible levels [[Figure XA]], indicating that the stochastic approximation procedure was implemented correctly and worked as the mathematical theory predicts.  

![](estimates.pdf)

For the larger landscape, I found that the stochastic approximation approach achieved reasonably good performance after less than a minute of optimization [Figure XB]. With additional time, was able to recover most of the variance in species’ pairwise interactions from observational data ($R^2 = 0.66$; Figure YA), and nearly all of the variance in their responses to environmental variables ($R^2 = 0.95$, not shown).

While the maximum likelihood estimates produced by the Markov network worked well, the sample correlation, explained a negligible fraction of the variance in species’ pairwise interactions ($R^2 = 0.03$, Figure YB).  To the extent that ecologists’ other test statistics for co-occurrence are similar to the sample correlation [[*evidence to be added to chapter 2*]], they can be expected to perform equally poorly. As shown previously, the partial correlation was a much better indicator of species’ true interactions than the sample correlation ($R^2 = 0.44$ Figure YC).

# Discussion

For decades, ecologists have relied on minor variations on the correlation coefficient as their test statistics for inferring species interactions from observational data @harris_estimating_2015. As shown here and in @harris_estimating_2015, however, these inferences can only be made reliably by methods that control for other species in the network, such as partial correlations or Markov networks.  The biggest computational problem with large Markov networks is the impossibility of averaging over all their possible states, but these results demonstrate that this step can be avoided.  Stochastic approximation is able to recover the same estimates as exact methods while scaling gracefully to networks with hundreds of species.

The largest downside of using stochastic approximation instead of the exact methods introduced in @harris_estimating_2015 is the difficulty in generating confidence intervals.  The `rosalia` package can produce confidence intervals based on the Hessian matrix, but it is not feasible to calculate this matrix for large networks.  It may turn out that the best way to generate confidence intervals for large networks is by repeatedly fitting the model to bootstrapped samples of the data. Alternatively, ecologists may be able to take advantage of the advanced Monte Carlo techniques introduced in @murray_mcmc_2012 to sample from the posterior distribution over possible parameter values, which could be used to generate credible intervals for the parameter estimates. Other advanced Monte Carlo methods [e.g. @salakhutdinov_learning_2009] may also speed up convergence to the maximum likelihood estimate in cases where serial autocorrelation in the Gibbs sampler is too strong for effectively sampling the space of possible landscapes.

As the number of potentially-interacting species increases, the number of adjustable parameters increases even faster, so overfitting becomes a major concern. Fortunately, a number of good regularizers have been proposed.  Of these, some of the most interesting options include $L_1$ regularization, which ensures that many of the estimated coefficients are exactly zero [[refs]].  This sparsity matches ecologists’ intuition that many species from different guilds are unlikely to interact much at all [[refs]], and also produces computational benefits for model estimation. Of course, the best regularizers will take advantage of prior ecological knowledge (e.g. from field experiments, natural history, or trait data) to provide information about individual pairwise interactions, rather than about their overall distribution.

Ecologists could expand beyond simple Markov networks in a number of ways that would improve their ability to address a wider range of questions.  This paper demonstrated that it is possible to simultaneously estimate species’ responses to the abiotic and environment and to one another, but many other extensions are possible. For example, ecologists could condition the model on variables whose values have not been measured (e.g. partially-observed Markov networks, or the approximate networks in the `mistnet` package). This would allow ecologists to account for measurement error and for other ecologically-important factors that can be difficult to measure. Ecologists should also explore higher-order networks, where one species’ presence can affect the relationship between two other species.

# References
